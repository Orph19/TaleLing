# What is TaleLing?
Hi. My name is Jhosver. TaleLing is a web app I created based on the brain's natural ability to learn a language effortlessly when it receives understandable information in the target language.

# Stories
A fiction book can make one get lost in it, eagerly turning pages to see what happens next. It is quite an immersive and effortless situation. But what else can be obtained from it apart from going to a different world? What if you could use this to learn a new language? 

# A language story
Language learning has been *gamified*, *systematized*, and offered widely throughout the world as a rigid service. But any healthy child learns their native language without putting any effort into it. You and I learned a language like that, right? It happened naturally. Then, why is it that one has to struggle to learn a different language?

When I started learning English, I experimented with a few ways of receiving information in English: first, only hearing and watching; after, I tried hearing, watching, and reading; then, only reading. It was clear that none of them worked, but then this combination appeared: seeing and reading.

## Getting acostumed
After years of only reading things in Spanish, I was not accustomed to seeing a whole text written in English, much less reading it. So, to start and avoid getting overwhelmed, I asked myself this: what has small sentences (or short text content) combined with visual aid?

That was the key. After huge immersion, I soon got completely accustomed to reading written English, and large texts looked like something with meaning instead of just a big block of letters.
 

## Learning a language

I'm skipping a few details, but the core idea is to tackle small chunks of text, have an aid to understand the meaning of the words (images and a translator), AND feel totally immersed in what is being read. This is the secret to learning any language fast and effortlessly.

It helps to pronounce what is being read (aloud or not). The point is to forget about your native language, so even if you know the direct translation of a word, do not use it. Just read the word as it is, however you can; the pronunciation can be enhanced later. For example, how would you read this: "Esto no es una palabra"? If you know a bit of Spanish, maybe you started finding the translation of "esto," which is "this," and then holding it to link it with the rest, like "this no es una palabra," and then going for the next word. But that sentence is in Spanish, so it is not "this"; it is "esto." Read it as "esto" and keep in mind that the meaning of "esto" is the same as when you use the word "this." 
 
For learning a language with a different writing system (like Chinese or Japanese), I thought it would be essential to first learn how to read it. For English or Spanish, it is simpler—same letters, similar sounds—but for languages with a different type of system, it may be useful to first have a reference of what to pronounce when seeing something like: 愛. This is only an intuition; I did not test it, but it makes sense.

A community can help to boost or even sustain the learning journey. It does not have to be a "language learning" community but rather one that natively talks in your target language. A comments section or similar is extremely useful because you could finish reading what you were reading and immediately go to the comments and try to understand what they are saying. This not only gives a sense of "this word is *really* used by them" but also the feeling of knowing that you can understand what they are saying and even interact once you get accustomed to their language.  


# TaleLing

[![TaleLing Demo](https://img.youtube.com/vi/hy5QkUKofqo/0.jpg)](https://www.youtube.com/watch?v=hy5QkUKofqo)

I created TaleLing as a resource that includes all of that in one. This repository contains all the code for TaleLing. It started as a project for a hackathon on [Devpost](https://devpost.com/software/tale-ling). After that, I decided to make it real and see if it could help anyone. From the Devpost project to the current version, it was a wide journey.

## No code experience
I coded for the first time a few years ago, but to me, it appeared vague, so I stopped coding. This year I started using Python and trying to see the logic of coding. A bit after that was when I tried out making a web app for a hackathon on Devpost. I had no clue how to do it, but AI helped.

## Vibe coding? 
I'm not sure what that is, but months ago, AI was unreliable, and weeks ago, it still was. Anyway, I used AI to code the basics and see how developers coded in reality. I made many things, tweaked the things AI made, and in the case of the frontend, it was all made with prompts. There were many bugs, *many*, but after many "conversations" with AI and after many days of coding things myself (following what I saw in the AI outputs), it was done. At some point, I started using some basic concepts like Separation of Concerns (SoC) and using reusable functions to reduce bugs.

## End of the journey
I decided not to update the app from here on. I made this repository with the purpose of first, sharing a way to learn languages, and second, sharing TaleLing as the starting point of a web app built on that learning approach. You can run it locally (although some setup is needed), try it out [here](https://taleling.pages.dev) (if you are reading this many years later, a few things could have ended up broken[^1]), or if you are interested in contributing, you are more than welcome to do so and set things up for anyone to keep using it.

There was no feedback in the brief period the app received users, but it looks like quite a few were curious about the app, and some signed up too, so the concept could end up working with a new design or as new ideas come up to truly reach that *I* in A*I* for generating immersive text and image-based content.

The moment to say goodbye has come; this is the end. Thanks for reading. Welcome to TaleLing.

[^1]: A big part of the backend's logic worked with a paid service. Although there were free, limited credits, I have now closed the service, so many things probably won't work. If the logic still works, then the only affected feature is image generation.
